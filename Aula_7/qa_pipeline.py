import os

# LangChain
from langchain.embeddings import SentenceTransformerEmbeddings
from langchain.vectorstores import FAISS
from langchain.docstore.document import Document
from langchain.chains import RetrievalQA
from langchain.llms import HuggingFacePipeline

# Transformers
from transformers import pipeline

# -----------------------------------------------------------------------------
# 1. Configura√ß√£o do modelo LLM local (text-generation)
# -----------------------------------------------------------------------------
def carregar_llm_local():
    gerador = pipeline(
        "text-generation",
        model="distilgpt2",
        max_new_tokens=50,
        do_sample=True,
        temperature=0.7
    )
    return HuggingFacePipeline(pipeline=gerador)

# -----------------------------------------------------------------------------
# 2. Cria√ß√£o de documentos de exemplo
# -----------------------------------------------------------------------------
def dividir_texto(texto, tamanho_chunk=200):
    texto_limpo = " ".join(texto.split())
    return [texto_limpo[i:i + tamanho_chunk] for i in range(0, len(texto_limpo), tamanho_chunk)]

def carregar_documentos():
    textos = [
        """Arquitetura em Camadas (Layered Architecture) √© um estilo de arquitetura de software 
        onde as responsabilidades s√£o organizadas em camadas...""",
        """A Arquitetura de Microsservi√ßos incentiva a cria√ß√£o de v√°rios servi√ßos pequenos e 
        independentes...""",
        """Um Mon√≥lito √© um estilo de arquitetura onde todo o c√≥digo e responsabilidades 
        ficam unificados em uma √∫nica base...""",
        """Domain-Driven Design (DDD) enfatiza a modelagem do dom√≠nio de neg√≥cio..."""
    ]

    docs = []
    for i, txt in enumerate(textos, start=1):
        for pedaco in dividir_texto(txt, 150):
            docs.append(Document(page_content=pedaco, metadata={"fonte": f"doc_{i}"}))
    return docs

# -----------------------------------------------------------------------------
# 3. Constru√ß√£o do √≠ndice vetorial FAISS com embeddings
# -----------------------------------------------------------------------------
def construir_index(docs):
    embeddings = SentenceTransformerEmbeddings(model_name="all-MiniLM-L6-v2")
    return FAISS.from_documents(docs, embeddings)

# -----------------------------------------------------------------------------
# 4. Constru√ß√£o da cadeia de Pergunta e Resposta
# -----------------------------------------------------------------------------
def criar_qa_chain(llm, index):
    return RetrievalQA.from_chain_type(
        llm=llm,
        chain_type="stuff",
        retriever=index.as_retriever()
    )

# -----------------------------------------------------------------------------
# 5. Execu√ß√£o das perguntas
# -----------------------------------------------------------------------------
def rodar_perguntas(qa_chain):
    perguntas = [
        "O que √© uma arquitetura em camadas e que camadas ela normalmente possui?",
        "Quais s√£o os benef√≠cios de uma arquitetura de microsservi√ßos?",
        "Explique as vantagens de ter uma arquitetura monol√≠tica.",
        "O que √© Domain-Driven Design (DDD) e por que ele √© √∫til?"
    ]
    for i, pergunta in enumerate(perguntas, start=1):
        print(f"\n=== Pergunta {i}: {pergunta}")
        resposta = qa_chain.run(pergunta)
        print("Resposta:", resposta)

# -----------------------------------------------------------------------------
# Fun√ß√£o principal
# -----------------------------------------------------------------------------
def main():
    print("üöÄ Carregando modelo...")
    llm = carregar_llm_local()

    print("üìÑ Carregando documentos...")
    docs = carregar_documentos()

    print("üì¶ Criando √≠ndice vetorial...")
    index = construir_index(docs)

    print("üß† Criando cadeia de perguntas e respostas...")
    qa_chain = criar_qa_chain(llm, index)

    print("‚ùì Respondendo perguntas...")
    rodar_perguntas(qa_chain)

if __name__ == "__main__":
    main()
